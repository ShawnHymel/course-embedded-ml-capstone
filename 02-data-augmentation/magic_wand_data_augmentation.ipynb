{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Magic Wand Data Augmentation\n",
        "\n",
        "[![Open In Colab <](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ShawnHymel/course-embedded-ml-capstone/blob/master/02-data-augmentation/magic_wand_data_augmentation.ipynb)\n",
        "\n",
        "Perform data augmentation on the magic wand dataset by splicing different samples together. This is an optional project. Upload your magic wand dataset (as a zip file, i.e. dataset.zip) to */content* and run the cells below to complete the data augmentation.\n",
        "\n",
        "Author: EdgeImpulse, Inc.<br>\n",
        "Date: July 28, 2022<br>\n",
        "License: Apache-2.0"
      ],
      "metadata": {
        "id": "jsoxfsLPXejV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Read data from CSV files\n",
        "\n",
        "Read each CSV, verify that the data (and header) are valid, save the data in Numpy format, and save the associated filename in a list."
      ],
      "metadata": {
        "id": "SAXp9Uw-VE6o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZ2UphF3XXTW"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import uuid\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Settings\n",
        "\n",
        "# Path information\n",
        "HOME_PATH = \"/content\"                # Location of the working directory\n",
        "DATASET_ZIP = \"/content/dataset.zip\"  # Name of the .zip file containing your original dataset\n",
        "DATASET_PATH = \"/content/dataset\"     # Upload your .csv samples to this directory\n",
        "OUT_PATH = \"/content/out\"             # Where output files go (will be deleted and recreated)\n",
        "OUT_ZIP = \"/content/out-augmented.zip\"        # Where to store the zipped output files\n",
        "CLASS_IDLE = \"_idle\"                  # Name of idle class\n",
        "CLASS_UNKNOWN = \"_unknown\"            # Name of unknown class\n",
        "AUGMENT_SHIFT_PERCENT = 0.2           # Amount to shift a sample for augmentation\n",
        "UNKNOWN_SHIFT_PERCENT = 0.5           # Amount to shift for new unknown samples"
      ],
      "metadata": {
        "id": "pjsOUZwlYqjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Unzip files to dataset directory\n",
        "%cd {HOME_PATH}\n",
        "!mkdir {DATASET_PATH}\n",
        "!unzip -q -d {DATASET_PATH} {DATASET_ZIP}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT6sDbHB8CZ1",
        "outputId": "2c86564e-9be0-43aa-fb76-4f683a00b7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "mkdir: cannot create directory ‘/content/dataset’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Read in .csv files to construct our data in a numpy array\n",
        "\n",
        "X_all = []\n",
        "filenames = []\n",
        "first_sample = True\n",
        "channel_names = None\n",
        "sample_shape = None\n",
        "\n",
        "# Loop through all files in our dataset\n",
        "for filename in os.listdir(DATASET_PATH):\n",
        "\n",
        "  # Check if the path is a file\n",
        "  filepath = os.path.join(DATASET_PATH, filename)\n",
        "  if not os.path.isfile(filepath):\n",
        "    continue\n",
        "\n",
        "  # Read CSV file\n",
        "  try:\n",
        "    data = np.genfromtxt(filepath, \n",
        "                        dtype=float,\n",
        "                        delimiter=',',\n",
        "                        names=True)\n",
        "  except Exception as e:\n",
        "    print(\"Could not parse\", filepath, \" - skipping.\")\n",
        "\n",
        "  # Get length of the sample\n",
        "  num_readings = data.shape[0]\n",
        "\n",
        "  # Extract sample rate (in milliseconds), header (without timestamp), and shape info (without \n",
        "  # timestamp) from the first sample we read\n",
        "  if first_sample:\n",
        "    channel_names = data.dtype.names\n",
        "    sample_shape = (num_readings, len(channel_names))\n",
        "    first_sample = False\n",
        "\n",
        "  # Check to make sure the new sample conforms to the first sample\n",
        "  else:\n",
        "\n",
        "    # Check header\n",
        "    if data.dtype.names != channel_names:\n",
        "      print(\"Header does not match. Skipping\", filename)\n",
        "      continue\n",
        "\n",
        "    # Check shape\n",
        "    if (num_readings, len(channel_names)) != sample_shape:\n",
        "      print(\"Shape does not match. Skipping\", filename)\n",
        "      continue\n",
        "\n",
        "  # Create sample (drop timestamp column)\n",
        "  sample = np.zeros(sample_shape)\n",
        "  for i in range(num_readings):\n",
        "    sample[i, :] = np.array(data[i].item())\n",
        "\n",
        "  # Append to our dataset\n",
        "  X_all.append(sample)\n",
        "\n",
        "  # Append the filename to our list of filenames\n",
        "  filenames.append(filename)\n",
        "\n",
        "# Convert the dataset into a numpy array\n",
        "X_all = np.array(X_all)\n",
        "\n",
        "# Get number of samples and channels\n",
        "num_samples = X_all.shape[0]\n",
        "num_channels = len(channel_names)\n",
        "\n",
        "print(\"Header:\", channel_names)\n",
        "print(\"Dataset shape:\", X_all.shape)\n",
        "print(\"Number of samples:\", num_samples)\n",
        "print(\"Number of files\", len(filenames))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7K13HsdYsEH",
        "outputId": "024fdb2e-29a2-4622-879d-fdc1d4d26d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Header: ('timestamp', 'accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ')\n",
            "Dataset shape: (648, 150, 7)\n",
            "Number of samples: 648\n",
            "Number of files 648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Create a list of labels that line up with the samples\n",
        "\n",
        "# Create list of labels\n",
        "labels = []\n",
        "for filename in filenames:\n",
        "  labels.append(filename.split('.')[0])\n",
        "\n",
        "# Calculate the number of classes\n",
        "classes = list(set(labels))\n",
        "classes.sort()\n",
        "\n",
        "# Show the classes\n",
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0NkyOHSYr2P",
        "outputId": "60f46275-13a1-42d6-d247-99980f7b9d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['_idle', '_unknown', 'alpha', 'beta', 'gamma']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Helper functions\n",
        "\n",
        "Helper functions to shift and append/prepend data as well as writing new samples to .csv files."
      ],
      "metadata": {
        "id": "LMb24rr0XmHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shift_and_add(sample_orig, sample_add, num_shift, keep_first_col=False):\n",
        "  \"\"\"\n",
        "  Shift a sample by some amount and prepend/append samples from another sample\n",
        "\n",
        "  :param sample_orig: Original sample you wish to shift\n",
        "  :param sample_add: Sample that you want to draw from for prepending/appending\n",
        "  :param num_shift: Number of readings that you want to shift by. Positive to shift right, negative to shift left\n",
        "  :param keep_first_col: True to keep first column readings (timestamps). False to shift first column readings.\n",
        "  :raise ValueError: if abs(num_shift) is greater than the length of either sample_orig or sample_add\n",
        "  :return: new Numpy sample\n",
        "  \"\"\"\n",
        "  # Make sure that the shifted amount is not more than the sample length\n",
        "  if (abs(num_shift) > sample_orig.shape[0]) or (abs(num_shift) > sample_add.shape[0]):\n",
        "    raise ValueError(\"Shift amount is greater than one of the sample lengths\")\n",
        "\n",
        "  # Create a new sample the same shape as our sample\n",
        "  sample_aug = np.zeros(sample_orig.shape)\n",
        "\n",
        "  # Determine if we shift left or right\n",
        "  if num_shift < 0:\n",
        "\n",
        "    # Shift sample to the left by some amount and append start of the given add sample\n",
        "    num_shift = abs(num_shift)\n",
        "    sample_aug[0:(sample_orig.shape[0] - num_shift), :] = sample_orig[num_shift:, :]\n",
        "    sample_aug[(sample_orig.shape[0] - num_shift):, :] = sample_add[0:num_shift, :]\n",
        "\n",
        "  else:\n",
        "\n",
        "    # Shift right by some amount and prepend the end of the given sample\n",
        "    sample_aug[num_shift:, :] = sample_orig[0:(sample_orig.shape[0] - num_shift), :]\n",
        "    sample_aug[:num_shift, :] = sample_add[(sample_add.shape[0] - num_shift):, :]\n",
        "\n",
        "  # Copy over first column if requested\n",
        "  if keep_first_col:\n",
        "    sample_aug[:, 0] = sample_orig[:, 0]\n",
        "\n",
        "  return sample_aug"
      ],
      "metadata": {
        "id": "1zi0A7UHlDnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_sample_csv(sample, header, label, path, debug=False):\n",
        "  \"\"\"\n",
        "  Write a given sample to a CSV file.\n",
        "\n",
        "  :param sample: Numpy array of the sample to write\n",
        "  :param header: Names of the different channels in the sample\n",
        "  :parm label: String containing the label of the sample\n",
        "  :param path: Location of directory where to create the CSV file\n",
        "  \"\"\"\n",
        "  # Generate unique filename (last 12 characters from uuid4 method) and\n",
        "  # make sure it does not conflict with any existing filenames\n",
        "  while True:\n",
        "    uid = str(uuid.uuid4())[-12:]\n",
        "    filename = label + \".\" + uid + \".csv\"\n",
        "    if not os.path.exists(os.path.join(path, filename)):\n",
        "      break\n",
        "\n",
        "  # Save new augmented sample to file\n",
        "  file_path = os.path.join(path, filename)\n",
        "  with open(file_path, 'w') as f:\n",
        "    csv_writer = csv.writer(f, delimiter=',')\n",
        "    csv_writer.writerow(header)\n",
        "    csv_writer.writerows(sample)\n",
        "\n",
        "  # Print out path to file\n",
        "  if debug:\n",
        "    print(\"Wrote:\", file_path)"
      ],
      "metadata": {
        "id": "yPQm8IKtUnA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Do the augmentation\n",
        "\n",
        "Shift samples over by some amount and append/prepend data from another sample to keep the same size."
      ],
      "metadata": {
        "id": "KIXqN3Ax71UZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Delete output directory (if it exists) and recreate it\n",
        "if os.path.exists(OUT_PATH):\n",
        "  shutil.rmtree(OUT_PATH)\n",
        "os.makedirs(OUT_PATH)"
      ],
      "metadata": {
        "id": "P9vvUOp75dlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Copy original dataset files to our output directory\n",
        "counter = 0\n",
        "for filename in os.listdir(DATASET_PATH):\n",
        "  if not os.path.isdir(os.path.join(DATASET_PATH, filename)):\n",
        "    shutil.copy(os.path.join(DATASET_PATH, filename), os.path.join(OUT_PATH, filename))\n",
        "    counter += 1\n",
        "print(\"Copied\", counter, \"files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4dj9oO-6S-w",
        "outputId": "13c9a132-f2b0-4d4d-a6a7-63904c9da598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied 648 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Initialize our counters here in case we want to run the augmentation cells multiple times\n",
        "new_sample_counter = 0\n",
        "unknown_counter = 0"
      ],
      "metadata": {
        "id": "2qMIVG3mZy6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Create new augmented samples for all but our \"unknown\" class\n",
        "# Loop through all samples\n",
        "for idx in range(X_all.shape[0]):\n",
        "\n",
        "  # Choose random idle sample\n",
        "  idle_idxs = np.where(np.array(labels) == CLASS_IDLE)[0]\n",
        "  idle_idx = np.random.choice(idle_idxs)\n",
        "\n",
        "  # Get original sample and idle sample\n",
        "  sample_orig = X_all[idx]\n",
        "  sample_add = X_all[idle_idx]\n",
        "\n",
        "  # Get the label\n",
        "  label = filenames[idx].split('.')[0]\n",
        "\n",
        "  # Don't augment unknown samples (we'll do that later)\n",
        "  if label == CLASS_UNKNOWN:\n",
        "    continue\n",
        "\n",
        "  # Calculate the amount to shift by\n",
        "  num_shift = int(AUGMENT_SHIFT_PERCENT * sample_orig.shape[0])\n",
        "\n",
        "  # Shift the sample to the right and write to file\n",
        "  sample_aug = shift_and_add(sample_orig, sample_add, num_shift, keep_first_col=True)\n",
        "  write_sample_csv(sample_aug, channel_names, label, OUT_PATH)\n",
        "\n",
        "  # Shift the sample to the left and write to file\n",
        "  sample_aug = shift_and_add(sample_orig, sample_add, (-1 * num_shift), keep_first_col=True)\n",
        "  write_sample_csv(sample_aug, channel_names, label, OUT_PATH)\n",
        "\n",
        "  # Count the number of new files we created\n",
        "  new_sample_counter += 2\n",
        "\n",
        "# Show the number of new files we created\n",
        "print(\"Created\", new_sample_counter, \"new samples\")"
      ],
      "metadata": {
        "id": "JLbMKgejaUKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2a02281-797f-4a7c-bb97-dd3f79368985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 5170 new samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Create new unknown samples by putting two halves of different samples together\n",
        "\n",
        "# Estimate the number of new augmented samples we added per class in the last cell\n",
        "num_aug_samples_per_class = int(new_sample_counter / (len(classes) - 1))\n",
        "\n",
        "# Loop through all samples\n",
        "for idx in range(X_all.shape[0]):\n",
        "\n",
        "  # To maintain a balanced dataset, don't add more samples than other classes\n",
        "  if unknown_counter >= num_aug_samples_per_class:\n",
        "    break\n",
        "\n",
        "  # Get original sample and random sample\n",
        "  sample_orig = X_all[idx]\n",
        "  sample_add = X_all[np.random.randint(num_samples)]\n",
        "\n",
        "  # Get the label\n",
        "  label = filenames[idx].split('.')[0]\n",
        "\n",
        "  # Don't augment unknown samples (we don't need more)\n",
        "  if label != CLASS_UNKNOWN:\n",
        "    continue\n",
        "\n",
        "  # However, our new sample should be classified as \"unknown\"\n",
        "  label = CLASS_UNKNOWN\n",
        "\n",
        "  # Calculate the amount to shift by\n",
        "  num_shift = int(UNKNOWN_SHIFT_PERCENT * sample_orig.shape[0])\n",
        "\n",
        "  # Shift the sample to the right and write to file\n",
        "  sample_aug = shift_and_add(sample_orig, sample_add, num_shift, keep_first_col=True)\n",
        "  write_sample_csv(sample_aug, channel_names, label, OUT_PATH)\n",
        "\n",
        "  # Shift the sample to the left and write to file\n",
        "  sample_aug = shift_and_add(sample_orig, sample_add, (-1 * num_shift), keep_first_col=True)\n",
        "  write_sample_csv(sample_aug, channel_names, label, OUT_PATH)\n",
        "\n",
        "  # Count the number of new files we created\n",
        "  unknown_counter += 2\n",
        "\n",
        "# Show the number of new files we created\n",
        "print(\"Created\", unknown_counter, \"new samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYRcIQUOaXgV",
        "outputId": "ae73c434-8dda-489d-da59-c4b164a9c754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 1292 new samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Zip output directory\n",
        "%cd {OUT_PATH}\n",
        "!zip -FS -r -q {OUT_ZIP} *\n",
        "%cd {HOME_PATH}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1wv-rEkZ9Fz",
        "outputId": "98ceca54-48bd-4a89-d90a-17af16b3ff69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/out\n",
            "/content\n"
          ]
        }
      ]
    }
  ]
}