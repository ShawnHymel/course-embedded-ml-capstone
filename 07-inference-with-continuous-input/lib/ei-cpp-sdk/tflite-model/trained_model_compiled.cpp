/* Generated by Edge Impulse
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
// Generated on: 17.11.2022 22:38:22

#include <stdio.h>
#include <stdlib.h>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#if defined __GNUC__
#define ALIGN(X) __attribute__((aligned(X)))
#elif defined _MSC_VER
#define ALIGN(X) __declspec(align(X))
#elif defined __TASKING__
#define ALIGN(X) __align(X)
#endif

#ifndef EI_MAX_SCRATCH_BUFFER_COUNT
#define EI_MAX_SCRATCH_BUFFER_COUNT 4
#endif // EI_MAX_SCRATCH_BUFFER_COUNT

#ifndef EI_MAX_OVERFLOW_BUFFER_COUNT
#define EI_MAX_OVERFLOW_BUFFER_COUNT 10
#endif // EI_MAX_OVERFLOW_BUFFER_COUNT

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

constexpr int kTensorArenaSize = 3168;

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};
enum used_operators_e {
  OP_RESHAPE, OP_CONV_2D, OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};
struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};
struct NodeInfo_t { // subset of TfLiteNode used for initialization from constant memory
  struct TfLiteIntArray* inputs;
  struct TfLiteIntArray* outputs;
  void* builtin_data;
  used_operators_e used_op_index;
};

TfLiteContext ctx{};
TfLiteTensor tflTensors[18];
TfLiteEvalTensor tflEvalTensors[18];
TfLiteRegistration registrations[OP_LAST];
TfLiteNode tflNodes[7];

const TfArray<2, int> tensor_dimension0 = { 2, { 1,900 } };
const TfArray<1, float> quant0_scale = { 1, { 0.10501408576965332, } };
const TfArray<1, int> quant0_zero = { 1, { -1 } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const ALIGN(16) int32_t tensor_data1[4] = { 1, 1, 150, 6, };
const TfArray<1, int> tensor_dimension1 = { 1, { 4 } };
const ALIGN(8) int32_t tensor_data2[2] = { -1, 224, };
const TfArray<1, int> tensor_dimension2 = { 1, { 2 } };
const ALIGN(16) int8_t tensor_data3[16*1*9*6] = { 
  /* [0][0][][] */ -41,-124,-9,73,17,-96, 1,-91,-56,10,-78,-62, 73,-127,-11,-28,-64,40, -57,-54,62,56,-18,37, 23,17,-20,-8,-26,23, -30,19,6,-65,15,-2, 93,-33,-4,-28,-2,34, 74,67,-4,-21,-19,42, -48,3,71,1,4,9, 
  /* [1][0][][] */ 17,60,23,36,-75,3, 66,71,8,34,-121,-60, 52,81,-40,-9,-24,-49, -5,83,-22,4,-89,46, 48,57,-52,-17,-58,-38, 8,127,83,1,-76,-49, 39,17,-29,86,-113,19, 26,56,88,-43,41,-33, -14,27,0,-82,-29,50, 
  /* [2][0][][] */ 35,-127,-65,-78,27,37, 62,-79,26,4,22,19, -37,-38,-45,-64,98,23, -10,-5,-33,-18,-11,31, -30,58,69,60,75,-4, -46,-15,31,-65,29,37, 3,44,86,-29,-44,92, 44,108,-17,51,54,37, -68,40,68,-50,-53,111, 
  /* [3][0][][] */ -67,-35,125,-17,38,22, 7,51,67,-49,47,56, 46,3,21,14,11,-18, -47,19,23,19,64,33, -18,-33,-9,-8,21,-34, 9,76,-19,-19,31,30, -29,32,-76,69,18,21, 60,71,-25,81,67,-15, 80,51,-67,29,-22,-127, 
  /* [4][0][][] */ -45,-127,55,60,-14,-22, -44,-68,23,23,43,-21, -7,-59,74,40,78,-81, 40,-71,-5,-12,59,-82, -12,-16,-18,-41,81,-70, 3,-62,60,-12,44,-11, -11,35,78,57,2,-18, 43,-83,77,73,66,-102, -19,-30,85,116,87,-80, 
  /* [5][0][][] */ 25,-6,-27,49,49,61, 63,-47,-9,43,8,106, 3,46,-64,127,-59,33, 5,-49,-67,18,-12,71, -42,-49,-80,46,27,104, -35,-61,-47,96,-58,75, 30,5,-87,72,-20,26, 46,23,37,43,21,49, 75,29,-23,56,21,80, 
  /* [6][0][][] */ 18,-127,-74,104,-94,-27, 60,-9,-17,51,-56,-2, 8,-102,23,-28,-53,-13, 43,-78,-44,7,-38,-48, 3,-1,-23,-49,-71,-78, 16,60,-56,-68,12,30, -45,16,32,9,-81,43, -3,102,61,40,-46,14, -77,34,116,-3,-126,80, 
  /* [7][0][][] */ -2,-48,44,-10,-9,-77, 51,-21,-31,69,50,77, 88,-56,79,-25,20,0, 94,25,3,-2,-95,64, 79,-34,-38,55,-19,38, 14,58,79,72,16,57, 24,-73,-77,-21,-108,-42, 54,37,-67,-127,-77,-20, 7,-49,-8,-25,-104,84, 
  /* [8][0][][] */ -61,14,-21,-1,-72,28, -5,-95,19,-75,2,7, 3,6,-24,17,-28,24, -125,-75,33,7,34,-76, -74,-7,-22,82,-62,-29, -92,-35,-90,9,17,32, -58,-68,-23,-27,-58,-12, -24,-29,-75,-71,5,-43, -121,5,4,-127,18,-121, 
  /* [9][0][][] */ 14,-46,33,-124,-82,-91, 36,38,59,-49,-65,-104, 46,-9,95,-97,-104,-85, 3,-6,55,2,-6,-74, 55,41,-48,-66,9,-83, 55,17,23,-91,3,3, 3,26,45,49,-1,11, -88,-79,12,-19,51,-19, -68,-80,-97,-34,74,-127, 
  /* [10][0][][] */ -29,76,-74,110,47,127, 63,-67,-27,85,86,96, -7,-67,-37,31,1,95, -24,-9,-68,63,115,3, -30,-40,-46,-6,25,98, -36,-1,-31,99,12,100, -23,-48,13,57,-78,61, -55,37,-92,50,48,39, 7,-13,-52,73,-6,116, 
  /* [11][0][][] */ 58,19,-124,-13,60,-55, 57,-118,-49,-118,97,-114, -10,-56,-1,-78,-7,-26, 51,-105,5,-120,112,-3, 35,-17,-70,75,117,-101, 47,-127,-1,-11,86,-76, 52,-87,-38,-48,2,-56, -12,-89,36,79,97,-69, 76,-51,28,-107,94,83, 
  /* [12][0][][] */ -5,125,-42,-45,-33,99, -3,1,-68,-95,-50,-45, 15,12,-98,-88,-61,-56, 95,82,16,-40,-14,-24, 3,-62,-53,-74,-105,98, -36,98,29,-7,-4,97, 24,35,-127,-70,-24,52, -16,-24,-52,-108,23,-54, 40,37,-115,-106,-42,55, 
  /* [13][0][][] */ -15,-2,6,-4,-9,-18, -27,9,64,92,70,-40, -42,-35,43,93,18,32, -37,-21,-36,127,75,23, 36,-70,-37,65,-21,-87, -85,-55,44,114,77,28, 41,23,114,59,25,-82, -37,54,-14,109,66,51, -41,7,36,16,82,-3, 
  /* [14][0][][] */ -18,-22,-3,2,127,33, -16,33,3,-64,61,36, -53,-16,-22,-52,88,36, -43,40,-12,32,57,-78, -8,2,35,40,47,40, 30,-5,8,-41,4,-42, -61,4,83,23,72,-4, -37,-4,98,20,29,20, -61,21,75,22,-41,34, 
  /* [15][0][][] */ -25,-2,-74,72,52,-40, 71,-28,-13,-20,5,51, 36,-95,54,-1,-47,-38, -29,-10,6,54,0,37, -16,-5,-3,-51,-17,-59, -41,-67,88,-14,39,19, 34,-85,94,-47,-83,-20, -11,34,63,-13,9,52, -26,-19,127,-25,-2,83, 
};
const TfArray<4, int> tensor_dimension3 = { 4, { 16,1,9,6 } };
const TfArray<16, float> quant3_scale = { 16, { 0.0024378178641200066, 0.0022153526078909636, 0.0023209385108202696, 0.002730413805693388, 0.0027787103317677975, 0.0025417436845600605, 0.0021770275197923183, 0.0022867142688483, 0.002101727994158864, 0.0024195362348109484, 0.0022121095098555088, 0.0019967034459114075, 0.0019797759596258402, 0.0022881580516695976, 0.0027721107471734285, 0.002416541101410985, } };
const TfArray<16, int> quant3_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant3 = { (TfLiteFloatArray*)&quant3_scale, (TfLiteIntArray*)&quant3_zero, 0 };
const ALIGN(16) int32_t tensor_data4[16] = { -1309, -301, -658, -818, -435, -399, -1183, -54, 428, -1085, -274, -1241, -1011, -1621, -1315, -886, };
const TfArray<1, int> tensor_dimension4 = { 1, { 16 } };
const TfArray<16, float> quant4_scale = { 16, { 0.00025600520893931389, 0.00023264322953764349, 0.00024373123596888036, 0.00028673189808614552, 0.00029180373530834913, 0.00026691888342611492, 0.00022861854813527316, 0.00024013720394577831, 0.00022071103740017861, 0.00025408537476323545, 0.00023230265651363879, 0.00020968198077753186, 0.00020790436246898025, 0.00024028882035054266, 0.00029111068579368293, 0.00025377084966748953, } };
const TfArray<16, int> quant4_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant4 = { (TfLiteFloatArray*)&quant4_scale, (TfLiteIntArray*)&quant4_zero, 0 };
const ALIGN(16) int8_t tensor_data5[16*1*9*16] = { 
  /* [0][0][][] */ 3,20,-1,127,-44,-13,101,-45,59,-17,-78,18,-25,-20,10,1, 78,-19,65,71,-46,27,66,-35,45,-39,-95,51,-63,-60,-50,75, 37,29,37,51,-54,-52,-11,-70,-21,13,-65,54,-52,7,-14,44, 49,7,-39,64,0,0,15,15,27,21,-40,51,-89,-45,-89,1, 17,-19,-5,42,-50,11,39,51,-25,39,-6,42,-93,-31,-33,83, 98,-4,3,32,-19,-35,-9,23,-4,-44,-46,-11,-118,-39,-28,54, 96,-40,-24,65,12,-49,37,-22,-59,-46,-99,2,-114,-16,25,92, 68,7,-8,67,26,-13,32,21,-32,-34,-86,11,-75,38,-8,12, 63,-38,10,19,-29,-44,69,60,-18,-20,-104,-35,-93,-9,21,67, 
  /* [1][0][][] */ -21,-66,-4,14,-54,30,10,35,-50,-127,23,-45,-58,44,40,1, 23,-69,25,53,-55,10,-26,34,-12,-98,7,-18,-34,13,32,18, -4,-62,35,22,-57,-4,-25,11,-41,-71,23,-6,-41,-2,54,39, 37,-83,23,36,-67,-9,-14,-12,-35,-48,-21,-7,-32,-19,7,26, -5,-68,26,22,-52,-36,22,-8,-15,-12,6,-32,-40,14,32,15, 55,-36,-5,8,-52,-27,16,17,1,-50,11,-24,-43,-16,8,18, -13,-21,20,-8,-70,-52,19,-55,19,-38,8,-53,-19,12,42,29, -8,-14,41,18,-114,-40,21,-68,12,-50,49,-69,-11,-6,7,2, -81,18,70,19,-83,-72,-3,-65,7,-20,39,-92,3,22,50,-21, 
  /* [2][0][][] */ 1,57,-55,-48,-4,81,-28,-6,87,66,27,80,31,-12,-12,-34, 30,4,-12,-96,-13,74,44,27,71,91,100,94,70,44,48,-86, 54,20,-23,-47,-34,42,-13,11,36,32,85,59,52,-15,2,-12, 9,36,42,-29,-58,71,26,18,29,23,-4,27,73,25,0,-66, 23,69,16,-55,-106,-8,5,31,-8,-41,-31,9,68,1,-62,-77, 7,51,-20,-12,-119,48,-59,-47,31,-69,41,40,54,-22,-12,-42, -17,61,-21,-16,-82,64,-46,-59,56,-40,-32,-32,48,25,-86,-105, 25,-17,-32,-56,-63,13,-25,4,63,6,63,11,26,-21,-41,-51, -41,40,6,-38,-37,53,-24,-18,7,-8,7,6,-17,-39,-42,-127, 
  /* [3][0][][] */ 20,-81,39,57,-34,53,-6,43,-22,-4,38,55,-16,59,63,-4, 65,-119,58,52,-42,57,39,12,-19,-11,25,55,15,-1,39,29, 46,-1,60,50,-74,27,30,27,-44,-22,2,34,-29,16,26,15, 19,-52,28,56,-92,28,1,-35,-71,31,52,13,-45,-2,35,19, 28,8,37,2,-82,20,45,47,-28,-26,-20,6,-40,-34,24,0, 22,-35,60,52,-57,21,19,-11,-42,-3,12,-50,12,-43,25,46, 27,-13,41,42,-127,1,50,-40,-2,61,-12,-44,-32,-19,-13,5, 7,-2,39,14,-62,-15,38,-40,1,57,-19,-64,-44,6,-47,-3, -26,38,7,19,-81,-50,-1,-52,29,28,13,-17,11,1,-43,-8, 
  /* [4][0][][] */ 26,26,73,-6,30,-22,17,0,-23,30,1,5,17,-27,-41,29, 37,-20,66,27,16,26,20,1,2,69,-41,19,-8,-18,-82,-8, -14,7,38,-21,35,2,-3,-38,-6,5,-30,53,-18,6,-44,4, 20,-10,27,26,1,-26,8,-43,10,45,-58,31,-35,-13,-54,15, 10,20,38,15,52,-35,21,-33,-32,33,-32,1,3,-13,-53,-10, -19,10,27,7,27,-27,71,-52,-40,67,12,49,7,-22,-75,-20, -27,-10,48,21,-16,-27,41,-11,14,97,9,35,17,-10,-127,-33, 2,17,33,-2,-35,-1,33,-30,46,30,4,31,34,3,-69,-22, -9,37,-28,-40,-49,39,49,-26,16,44,18,17,-7,-8,-118,22, 
  /* [5][0][][] */ -9,-93,-89,22,64,30,-54,47,24,-99,-67,65,19,42,-6,-26, -30,-54,-27,9,72,23,-53,14,-25,-23,26,53,-28,-30,16,51, 10,-81,-18,-1,56,26,-74,-50,-47,36,10,66,3,3,53,30, -59,-99,-17,40,26,61,-127,8,-26,15,27,45,39,54,35,3, -34,-68,-1,47,65,74,-10,3,-35,-60,57,39,12,-37,6,-5, -35,-44,-56,28,38,6,-50,7,-32,-37,54,102,-2,-15,21,21, -20,-87,-23,-25,44,59,-79,13,10,-58,71,24,16,-75,-8,27, -19,-25,-16,-23,3,60,-40,-23,-60,5,14,22,-7,-100,-43,11, -14,-90,-15,11,65,17,-2,-15,-121,-67,-2,22,-90,-38,35,8, 
  /* [6][0][][] */ 11,36,-5,17,25,8,7,23,36,67,25,9,22,40,21,-6, -13,42,-30,-17,40,-20,3,-2,33,59,11,11,13,32,20,2, 25,6,-40,-12,17,-2,34,-22,-12,53,-4,-2,-15,18,9,2, -2,17,-32,-18,23,7,5,20,3,37,-34,-14,-39,10,-15,18, 23,19,-96,-24,27,-5,2,22,-16,23,5,-24,-48,-11,-45,20, -16,-2,-97,-65,22,0,-6,6,-1,-14,3,-26,-36,-35,-76,-2, -27,17,-71,-93,9,9,-10,-9,2,-14,-13,-10,-54,-39,-34,-15, -30,17,-65,-115,-4,-35,-51,-7,0,-11,-87,-7,-69,-21,-19,11, -17,21,-127,-107,26,-70,-30,19,-13,14,-98,-18,-66,-53,-30,-15, 
  /* [7][0][][] */ -2,-52,20,2,-7,-40,61,31,29,-25,-85,25,81,53,52,-14, -16,-52,-12,7,16,-60,15,45,19,14,-74,31,72,65,11,-15, -4,14,36,16,8,-99,14,2,28,-40,-80,18,47,28,6,-34, 21,21,39,8,23,-111,-22,62,-58,3,-58,42,-22,15,0,-4, 36,4,22,-15,5,-66,-10,48,-72,-29,-26,-24,-30,-8,29,-29, 12,-9,-21,-10,36,-98,-48,77,-39,-15,-93,18,12,-4,27,-22, 35,27,-30,6,24,-57,-46,53,-78,-14,-81,-20,-30,24,42,-54, 25,-18,-16,6,8,-52,-34,73,-17,-40,-58,16,30,36,45,-55, -9,-28,17,7,2,-127,32,60,-63,-54,-96,-31,56,23,22,-44, 
  /* [8][0][][] */ 25,-33,47,-29,-24,-56,45,16,29,-3,-104,16,13,-58,-26,54, 26,-24,42,-4,-14,-45,61,-11,14,-38,-59,-29,-14,-80,-5,56, 64,-30,37,28,-14,19,26,-10,-3,17,-20,12,-34,-51,-18,44, 73,-6,32,63,-53,-30,51,-11,-30,24,3,-65,-48,-49,-44,-1, 20,45,-2,25,-91,-11,-21,-16,-33,-21,7,-32,-20,-26,-51,-31, 4,35,5,20,-68,-37,-62,-1,2,45,34,26,-29,-118,-18,-127, -85,55,-43,-35,-31,-41,-69,-21,-35,34,-17,47,30,-100,-82,-70, -33,29,30,-46,4,-35,4,4,-14,-9,-53,-4,34,-50,-86,-9, 35,41,-8,-18,-7,13,45,-3,-2,-47,-49,3,16,-107,-123,-2, 
  /* [9][0][][] */ 15,-71,61,29,4,47,-3,35,-37,-47,76,-79,-49,36,61,-17, 11,-24,63,31,-8,27,54,51,-66,-28,48,-9,-21,26,15,-10, 34,-1,29,16,-68,59,25,64,-53,-74,13,-38,-22,46,-15,25, -16,-7,9,-3,-57,26,26,62,-64,-37,-29,-84,-30,-6,20,47, 54,-43,-28,-14,-27,16,22,11,-22,-15,32,-117,-55,16,8,-5, 13,24,42,-6,-17,-16,19,29,3,-17,26,-42,-43,59,4,19, -1,25,38,14,-26,-40,34,11,1,-41,-10,-77,-5,0,17,5, -11,25,-8,-1,-52,-36,60,40,-28,-54,16,-125,-38,8,17,47, 41,-6,-5,-16,-77,-2,13,9,16,-3,0,-127,-43,-25,60,22, 
  /* [10][0][][] */ 18,5,57,9,-50,-23,3,24,16,-8,-31,9,9,0,-7,-2, 44,-49,18,-7,-68,-8,69,19,21,23,-12,37,-2,-66,-51,35, 36,-69,10,35,-47,-17,-6,15,-39,11,-18,17,19,-88,-27,44, 48,-66,10,78,-53,-4,32,18,15,-24,4,20,-21,-40,-18,14, 69,-29,43,24,-85,-31,3,1,-2,-11,-15,25,-47,-72,-15,37, 80,-12,18,51,-40,17,66,-24,-21,-10,18,20,-21,-20,-13,61, 88,-34,51,30,-51,13,12,21,-16,41,-35,16,-64,-6,-30,43, 93,-64,58,41,-108,-47,61,20,-29,21,-33,33,-74,-21,11,48, 98,-59,42,32,-127,17,52,-3,-29,-12,-23,12,-30,-71,3,-10, 
  /* [11][0][][] */ 11,4,-3,26,31,-111,49,-5,15,27,-35,-21,12,45,7,55, 27,27,-16,62,39,-127,59,13,2,-13,-75,3,18,44,9,35, 3,13,38,29,8,-116,35,-35,40,-30,-71,-30,15,31,16,38, -19,-28,11,38,17,-47,40,-32,-8,-36,-30,-10,-3,4,-27,19, 10,19,51,67,-1,-72,67,-10,23,-42,-62,-65,-25,-8,-27,32, 46,20,20,36,-12,-72,-4,-13,-22,-3,-21,9,-26,47,33,31, 57,27,-24,34,-18,-13,52,17,27,-61,-58,-19,-95,79,-8,29, 41,-18,-48,53,11,-24,44,10,-4,-14,-71,17,-39,41,-25,-1, 75,15,-47,14,37,-53,8,76,-13,-57,-48,-1,3,23,-8,0, 
  /* [12][0][][] */ 40,37,-121,-54,-44,71,-5,-13,39,40,69,13,-12,-33,-13,-35, 53,36,-71,-65,-58,101,-14,52,24,57,49,36,-6,24,-10,-46, 44,-2,-41,-49,-3,89,-68,25,89,52,18,40,8,-46,-19,-31, -36,-4,1,4,-26,37,-72,37,64,36,20,48,-21,6,-15,-84, -24,39,-57,4,-16,24,-59,-19,127,78,70,61,-3,37,1,-112, -17,35,-14,-36,-36,106,-74,-47,22,45,17,60,-11,48,76,-28, -23,49,-8,-60,2,3,-73,-19,38,85,73,69,35,30,53,-72, 14,28,-40,22,59,26,-80,-42,21,27,-23,-5,-5,15,-40,-47, -32,59,6,-15,-10,28,-43,8,-5,55,9,-27,-10,10,-7,-10, 
  /* [13][0][][] */ 65,-54,45,79,14,-15,57,-1,-36,-5,31,-23,12,86,-21,-13, 36,-43,41,100,36,57,62,6,24,5,65,7,29,64,127,-6, -16,32,82,31,-6,77,-17,64,39,-101,3,-47,4,97,102,-25, 44,12,34,3,-37,14,73,42,11,-41,-48,-60,58,33,59,-40, -21,46,73,-4,-11,-11,58,20,-37,-40,-66,6,54,18,14,25, -27,2,12,-4,12,-91,0,-13,-79,27,-41,-6,40,28,20,56, 16,-10,58,-3,-4,-16,7,-3,-47,47,0,-5,-27,26,50,-9, 53,-65,75,11,32,-71,-19,-57,-99,15,1,-42,10,66,6,2, 5,-35,37,31,29,-16,-62,-23,-126,-38,47,11,-52,93,41,-42, 
  /* [14][0][][] */ 29,20,76,11,-127,83,-2,-23,-24,46,-86,8,58,-31,-13,-61, -12,49,54,-36,-75,36,33,25,-64,50,39,-39,21,-68,39,-50, -58,88,44,-80,-69,-61,30,83,2,111,-111,53,-25,-74,75,-21, -6,24,-12,-7,-31,-66,9,28,15,107,18,-12,22,-47,-68,77, 47,21,38,-63,62,29,15,-27,14,113,37,15,-31,2,-22,33, 59,-38,-5,35,62,54,-58,10,-21,121,27,-14,-59,87,-65,-19, 32,20,14,-32,85,-57,43,-73,9,106,71,0,-73,36,52,-9, -57,5,55,28,49,26,32,-79,-27,66,-19,25,-63,57,88,-29, -122,-16,25,-23,60,24,-32,-123,-37,13,56,17,-119,82,56,-68, 
  /* [15][0][][] */ -42,32,-72,-77,-27,-123,-127,37,-10,-58,-88,-63,-31,-77,-7,-10, -19,15,-40,-100,-2,-51,-124,61,-7,-49,-58,-76,-79,-67,-2,-18, -27,67,-79,-42,3,-31,-54,98,9,-88,-2,-45,-51,37,31,18, -56,32,-23,34,21,-43,-65,60,36,-21,13,-46,-3,-7,-16,-20, 12,36,-29,-18,-6,-11,24,73,35,-105,-34,-51,16,-20,-62,46, -61,54,-20,1,21,-10,20,30,50,-57,-24,-53,-23,-23,-89,39, -42,28,24,-19,-3,-45,-30,-17,36,-16,28,-72,46,20,-3,30, 9,52,62,-15,-5,-17,45,11,67,-70,18,-12,66,21,-25,14, 7,78,17,3,-15,-30,19,-14,42,-54,38,-35,2,11,11,40, 
};
const TfArray<4, int> tensor_dimension5 = { 4, { 16,1,9,16 } };
const TfArray<16, float> quant5_scale = { 16, { 0.0022098575718700886, 0.0035557257942855358, 0.0023472609464079142, 0.0030659683980047703, 0.0031181522645056248, 0.0026280607562512159, 0.0043029468506574631, 0.0028606716077774763, 0.003376741660758853, 0.0029046479612588882, 0.0032108258455991745, 0.0032990514300763607, 0.0024330916348844767, 0.0021105834748595953, 0.0019425043137744069, 0.0025809262879192829, } };
const TfArray<16, int> quant5_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant5 = { (TfLiteFloatArray*)&quant5_scale, (TfLiteIntArray*)&quant5_zero, 0 };
const ALIGN(16) int32_t tensor_data6[16] = { 377, 584, 380, -671, -1342, 314, 607, -168, 115, 5, -313, -489, -95, -2008, -1777, 2613, };
const TfArray<1, int> tensor_dimension6 = { 1, { 16 } };
const TfArray<16, float> quant6_scale = { 16, { 0.00014505645958706737, 0.00023340010375250131, 0.00015407570754177868, 0.00020125211449339986, 0.00020467750437092036, 0.00017250758537556976, 0.0002824481634888798, 0.00018777629884425551, 0.00022165146947372705, 0.00019066293316427618, 0.00021076065604574978, 0.00021655183809343725, 0.00015970968524925411, 0.00013854003918822855, 0.00012750721361953765, 0.00016941364447120577, } };
const TfArray<16, int> quant6_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant6 = { (TfLiteFloatArray*)&quant6_scale, (TfLiteIntArray*)&quant6_zero, 0 };
const ALIGN(16) int8_t tensor_data7[20*224] = { 
  -11, -34, 5, -31, -49, -25, -62, 14, -27, -32, -10, 1, -6, 4, 30, 39, -1, -4, -16, -12, 8, -22, -49, 31, -12, -9, -29, 64, -41, 35, 19, 67, -7, -3, -19, -10, -31, 40, -19, 17, 40, -14, -2, 29, -3, 4, 16, 50, -10, -49, 34, -19, -45, -2, 3, -16, -29, -6, 25, 26, 65, 60, 14, -17, 20, -35, 16, -6, 13, 56, -6, 15, 1, 18, -32, 10, 47, 4, 45, -40, 3, -20, 43, 12, -52, 31, -22, 9, -17, 6, -16, -2, -25, 62, 15, -30, 22, -3, -16, 9, -14, 44, -15, 50, -54, -47, 20, -4, 40, 54, -35, 20, 54, 9, 29, 0, -28, -5, -16, 52, -13, -78, 1, -19, 21, -21, -29, -56, 36, 12, 39, 24, -72, 9, 15, 49, -22, -29, -5, -23, 18, 7, 14, -49, -2, 9, 24, -12, -57, 19, 34, 15, -29, -66, 37, -19, 26, -42, -91, -38, -1, -35, 4, 41, -55, 8, 35, 24, -33, -32, 47, -73, -35, -5, -73, 27, 4, 56, 37, -1, -2, -27, -11, -29, 26, 3, 13, -100, 30, -5, 1, 32, -11, -21, 3, 19, -26, -36, -43, -7, 26, -11, -46, -121, 50, -55, -6, -15, -74, -8, -7, 28, -2, -11, -36, 5, -21, -33, -26, -80, 19, -35, -4, 38, 
  25, 59, -111, 29, -68, -16, 0, 56, -49, 44, -3, 29, -60, 14, -16, 24, -10, 71, -86, 2, 7, 4, 57, 1, -67, 31, 31, 10, -61, 33, -3, 56, -4, 4, -45, -29, 8, -65, -44, -48, -30, 23, 20, 8, -4, -2, 58, 57, -4, 5, -11, 45, 55, 0, 14, -11, -29, 3, 15, 28, 37, 28, 76, -27, -13, 51, 3, 29, 17, 17, 69, -11, -62, 18, 9, 45, 10, 25, 38, -3, 33, 60, -2, 33, 2, 38, 51, 5, -8, 0, -49, 48, 8, -16, 29, -29, 13, -12, -48, 12, 23, 23, 35, 16, -8, -55, -62, 51, 8, -36, 2, 2, -11, -43, -73, -14, 53, 6, 20, -7, -108, -86, -62, 39, 21, -72, 1, 7, 36, -36, -23, -80, 29, 46, 34, -2, -94, -67, -45, 34, 46, -65, 17, 13, 26, -54, -45, -96, 16, 8, 68, -63, -70, -49, -40, 13, -29, -100, -2, -34, -13, -43, -71, -87, 38, -14, 51, -30, -76, -114, -25, 15, -39, -41, -39, -21, -9, -32, -23, -54, 25, -14, 20, 36, -78, 31, -20, -13, -30, -40, -46, -3, -87, -17, 47, -46, 27, -29, 27, -8, 1, 32, -50, -40, 16, 2, -7, -12, -5, -10, 59, -18, 5, 33, 16, 49, -46, -8, 37, -67, 27, 24, 14, 57, 
  -56, 20, 62, 51, -6, 7, -11, 36, -24, 2, -23, -17, -3, 28, 6, 21, 6, 5, -8, 17, 8, 32, 28, 1, -20, -4, 40, 5, 31, 17, -29, -10, 38, 21, 31, 2, 52, 4, 7, -33, 8, -13, 3, -19, -20, -18, 23, -19, 41, 18, 9, 17, -4, 43, -9, 19, -20, 55, 60, 19, 45, 49, 39, -30, -52, -4, -20, 17, -12, 1, 4, -9, -20, 56, 59, 9, 43, 58, 44, -33, 33, 11, 2, -25, -32, -30, -26, 17, -47, -26, 25, 47, -34, -30, 59, -11, -23, 45, 14, 31, 69, 45, -33, 39, 2, 14, 20, -2, 2, -4, 36, -19, -32, 34, 18, 51, -5, -15, 13, 16, 5, 29, -35, 28, 26, 48, 24, -10, -62, 32, -19, 27, 1, 7, 19, 19, -23, 72, 28, -8, -11, 12, -6, -33, -1, 15, 43, 28, 6, -11, -7, 14, -40, 37, 2, 18, 38, 41, 9, 11, -53, 46, 27, 57, 45, -12, 36, 51, -8, 15, -23, -10, 27, -4, 31, -27, -50, 23, -1, 16, 29, -5, 44, 41, -8, 20, 26, 3, 23, 24, 2, -17, 33, -11, 15, 33, 44, 45, -16, 39, 13, 18, 10, 16, 2, -15, 8, -31, -12, -14, 27, -33, 35, 5, 27, 5, -10, -19, 32, 1, -25, 16, -1, -12, 
  -20, -90, -5, -21, 28, -4, -100, -7, -1, -26, 2, -10, 36, -14, 22, -2, 26, -69, -4, -34, 21, -13, -56, -36, 3, -44, 37, -16, -29, -29, 1, 21, 22, -87, 23, -42, 6, -25, -58, 40, 37, -61, 17, -23, 29, -9, 52, -19, 21, -73, 28, -16, 23, 1, -22, -8, 4, 17, 52, 37, -7, -32, 25, 12, 6, -14, 16, 29, 2, -20, -61, 39, -2, 3, 27, 22, -24, 35, 56, 16, 60, -46, -25, -23, 44, -8, -46, 54, -11, -2, 22, 62, -47, 0, 39, -6, 1, -29, 1, 25, 40, 38, -28, 15, 39, -16, 5, 48, 12, 8, 36, -45, 28, -36, -28, 24, -7, 21, -32, 35, 74, 21, 21, 38, -49, 61, 24, 3, 2, -74, -13, 14, 53, 49, -11, 19, 68, -7, 37, 39, 17, 45, -12, 7, 38, -28, 32, 32, 14, 65, -17, 56, 22, -17, 31, 43, 15, 37, -37, 33, -8, -23, 34, -3, -51, 54, 0, 37, 83, 27, 52, -19, -34, 9, 35, 19, -10, 8, -8, 14, -15, 43, -17, 78, 37, 5, 17, 9, -35, -3, -49, 52, 18, -21, 26, -19, 28, 47, -32, 44, 30, 31, -15, -57, 31, -2, -9, 9, 46, -51, 33, -11, 9, -5, -105, -17, 36, -17, 43, 13, -21, 20, 34, 40, 
  10, -65, -1, 20, -18, 17, -34, -1, -27, 0, 19, 36, 1, 22, 11, 32, 35, -38, 30, -28, -18, -21, -15, 22, -22, -3, 23, 38, 27, -2, 0, -24, -11, -43, 26, 13, 37, 15, 5, 40, 39, 40, -26, 58, -68, 6, 7, 6, 38, -43, -48, 30, 22, 39, -25, 66, -18, 22, -36, 26, -60, 25, -20, -29, 68, -9, -27, 17, 4, 10, -29, 31, 61, -52, -2, 34, -17, 55, 16, 4, 9, -37, -39, 12, -6, 11, 6, 50, 5, -14, 50, 24, 13, -14, 15, 25, 7, -89, 7, -33, -3, -27, -27, 31, 26, -28, 33, 31, -5, 60, 36, 45, 54, -34, -23, -8, -21, 16, -22, 23, -1, -20, -1, 6, -17, 4, -33, 25, 25, -45, -8, -5, 19, 26, 9, 75, 16, 16, 28, 6, -38, 4, 13, 12, -6, -65, 15, 23, 32, -12, -59, 9, 64, -24, 20, -16, -43, -4, -10, 19, 61, -85, 13, -13, -7, 3, -39, 54, 22, -22, -2, 31, -51, 56, 1, 61, 10, -24, 59, -1, -3, 0, -13, 24, 55, 19, 1, 1, -37, 59, 56, 34, -13, -24, -5, 36, -12, -26, -39, 19, 59, -1, 8, 50, -5, 41, -15, 29, 18, -97, 5, -31, 1, -12, -45, 67, 34, -30, -13, 63, -5, 50, 7, 0, 
  -14, 29, 20, -33, 8, -12, -38, 7, 53, 6, -13, -49, 22, -14, -11, 34, 35, -32, 20, 41, 14, 47, -22, 1, 16, 25, -28, -35, 41, -8, 26, 0, -39, 5, -4, 23, -22, 18, 24, 68, 16, -39, -38, -22, 16, 15, 13, -63, 32, -7, -80, -41, -6, 26, -20, 46, 40, -53, -59, 2, -42, -16, -20, -17, -8, -34, -63, -34, -48, 16, 18, -8, 34, 23, 4, 6, -47, 15, 2, 42, -19, 38, -49, 36, -42, 38, -23, -2, 14, -16, -14, -20, -42, -12, -8, 16, -8, 12, -87, -11, 34, 5, 42, -15, 2, -47, -30, 19, -40, 5, 18, -53, 12, -2, -73, -37, 7, 16, -37, 31, -6, -60, -21, -3, -12, 32, 35, 29, 52, -14, 47, 29, -6, 9, -19, -1, 25, -38, 44, -4, 11, -18, -30, 54, 47, 8, -34, -13, 33, 32, -22, 30, 75, -37, 29, 33, -1, -28, 1, -11, 48, -73, -28, 34, 41, -27, 3, 53, 70, 22, 3, 2, -19, 10, 27, 15, 34, -10, -40, -9, 46, -46, -5, 11, 78, 17, 46, -5, -33, -42, -21, 0, 42, -49, -12, 10, -13, 23, -24, -3, -6, 26, 22, 24, -67, -5, 9, 47, -1, -27, -37, -5, 9, -17, -9, 34, 53, 20, 22, 2, -84, 1, 5, 64, 
  5, 27, 23, 29, 25, 28, 3, -6, -3, -20, -10, 10, 7, -1, 50, -16, 31, 24, -5, -3, -16, 7, 72, 32, 42, 23, -13, 32, 6, 9, 11, 20, 36, 48, 21, 40, 38, -3, 30, 34, 11, -5, 34, 58, -28, 41, 43, -4, 7, 23, -42, 27, 11, -97, 43, -15, -5, 16, 32, 47, -7, -49, 4, -18, 19, 67, -65, 10, 17, -50, -32, -21, 10, 9, 9, -11, -65, -57, 0, 47, 14, 54, -28, -4, -3, -101, 68, -4, 0, 44, 51, 37, -4, 15, 6, 37, 38, 38, -18, 35, 12, -85, 0, -26, -17, 40, 28, 19, -23, -47, 20, 58, 29, 59, -12, 45, 47, -100, -23, -55, -10, 67, 69, 34, -20, -31, 24, 41, 0, 92, -45, 37, 42, -39, 42, -13, 57, 34, 41, 65, -9, 45, -19, 18, 63, 53, -64, 31, 43, -55, 31, -37, 13, -25, 15, 47, -26, -28, -37, 8, 27, 38, -58, 8, -9, -80, 25, -52, -5, -26, 21, 40, -77, -30, -19, -13, -19, -3, -24, -38, -24, -47, -3, -4, 35, -40, -5, 53, -66, 9, 38, -34, 37, 37, -46, -28, -18, 14, 27, 13, 8, -11, -15, -19, 51, -23, -14, -3, 19, -14, 4, -2, 34, 12, 71, 12, -13, 6, 8, -6, 13, -18, 23, -8, 
  52, 10, -5, -39, 30, -30, -16, -45, -5, -1, 36, -40, 21, -23, 19, 33, 3, 4, 25, 12, -16, -28, 11, -2, 39, -1, 20, 7, -24, -21, 30, -25, -23, 50, 6, 22, -12, 33, 85, -5, 11, 35, 6, -8, -33, 17, -3, -21, -46, 52, -27, 26, -25, 31, 47, 5, -1, 24, -6, 2, 10, 33, -77, -18, -9, 73, -28, 72, 13, -56, 9, -22, 36, 28, -10, -56, 26, 15, 44, -24, -13, 77, -44, 14, 6, -105, 18, -72, -14, -7, -12, -54, -9, 7, -21, 10, 9, 46, -17, 4, 45, -45, -7, 0, -8, -4, 26, -16, -28, 11, 49, 8, 65, 69, -41, -3, 37, 23, 12, -21, -49, -2, 44, 21, -26, -9, 11, -45, 12, 16, -22, 13, 32, -10, 47, 16, -12, 24, 37, -13, 44, 7, 34, -50, 1, 95, -26, 33, 28, 79, 8, -31, -52, 38, 45, 28, 30, 46, 30, -26, -1, 110, -23, 51, -24, 72, 18, -9, -17, 53, 15, -19, 49, 44, -12, -14, 2, 29, 9, 48, 18, 6, 15, -50, -21, 36, -2, 41, -20, 37, 24, 0, 15, 13, 4, 50, 14, 7, 64, -41, 19, 20, 20, 19, 26, -10, -3, 9, 6, 52, -27, -25, 2, 14, 2, 8, -68, -27, 61, -23, 6, 19, -1, 12, 
  -46, -58, 1, -61, -35, -50, -4, -26, -18, -17, -1, -81, 9, -57, -25, 58, -28, 8, -16, -39, -35, -10, 26, -3, 13, 13, -3, -49, -4, -64, -66, 17, 11, -46, 10, 23, -55, -16, -8, 38, -12, 38, 18, -45, -3, -39, -24, 67, 41, 6, -4, 22, -75, -76, -51, 29, -1, 59, 28, -2, 30, 18, 25, 35, 42, 32, 20, 53, 17, -62, -89, 28, -47, 62, 59, 42, -12, 59, 33, 25, -6, -2, -14, 29, -9, 3, -55, -29, 5, 82, 52, 42, -21, 33, 32, 51, 61, -2, -27, 53, -22, -30, -24, -8, -25, 37, 39, 56, -35, 63, 67, 4, 21, 75, 3, 21, -3, 2, 5, 5, -15, 11, 14, 34, 19, 50, 73, -33, 23, 5, -58, 33, 36, 34, -4, -15, 9, 0, -26, 21, -14, 22, 21, -82, 16, 48, -48, 14, -5, 12, 30, 50, 1, -42, -60, -13, 33, 17, 27, -86, 34, -43, -52, -101, -38, 26, 15, 23, -20, -96, -46, -10, 2, -19, -4, -95, -4, 0, -28, -71, -7, 26, 26, -25, -57, -65, -7, -14, 33, -34, 38, 16, -1, -64, 1, -45, -4, 22, 39, 37, -34, 5, -34, -28, 1, -57, -4, -7, -6, -33, 8, 8, -11, 24, 87, -19, -79, 34, 2, 4, -11, 13, -56, -56, 
  22, -20, 4, 45, -12, 14, -61, -12, 54, -2, 51, 3, -26, 3, 17, 38, 29, 23, 8, 8, -28, -5, -6, 3, -24, 5, 10, -9, 4, 14, -47, 23, 23, -3, -17, -3, -23, -24, 14, 4, -30, 19, -5, 14, -24, -38, 44, -26, 3, 45, -22, 11, -14, 4, 4, 11, 12, 64, 35, -18, -19, -29, -19, -14, 20, 74, -14, -3, 20, -50, -14, -43, 12, 8, 10, -19, 4, 46, 49, -19, 8, 19, -25, 25, 37, -22, 2, -4, 4, 53, 26, -19, -19, -26, 43, -19, 5, 41, 24, 12, -1, -7, 25, 17, -11, 28, 74, 34, 22, 46, 27, -23, -1, 16, -3, 33, -24, 2, -44, -14, 17, 58, 37, -12, -20, 43, 1, -22, 37, 42, -18, 57, 45, 4, -8, -35, 58, 80, 32, 32, 30, 27, 41, -17, 54, 21, 8, 55, 10, -37, -38, -51, -8, 34, 73, -12, 39, 36, 20, -36, 43, 117, 23, 40, 34, 27, 14, -76, 42, 8, 34, 42, -19, 56, 4, 7, 5, 43, 0, 27, 2, -51, 39, -80, 5, 60, -15, 29, 34, -3, 34, -48, -21, 18, -42, 44, 52, -61, -1, -41, 70, -5, 55, -2, -8, 30, 23, 6, 24, 37, -43, 12, 6, -79, 18, -55, -20, -8, 14, 15, -21, -35, 13, -11, 
  15, -18, -26, -46, 15, 23, 33, 18, 20, 5, 12, 20, 28, 24, -24, 25, -12, -39, 23, -51, 46, 22, -4, 2, 43, -20, 36, -6, 18, -36, 10, 37, -20, -54, -14, -38, 14, -51, 62, 70, 36, 14, -6, -13, -28, -8, -8, 25, 28, -44, -58, 15, -44, -76, 12, 7, -20, 39, 28, -29, -25, -4, -9, 36, -76, -81, -16, -71, -38, -55, 49, 49, -58, -6, -57, -62, -48, -25, -81, 49, -16, -25, -47, -84, -56, -43, 17, 15, -34, 15, 13, -40, -74, -34, -46, 35, -30, -18, -10, -40, -79, -93, 52, 11, -5, -25, 54, -82, -88, -60, -103, 30, -30, 40, -18, -27, -80, -113, 27, 28, -13, 41, -2, -27, -80, 6, -60, 92, -17, 7, -43, -1, -55, -73, 67, 39, -66, 15, 9, 21, -61, -18, -34, 81, -49, 53, -35, 7, -60, -76, 52, 28, -45, 13, 15, -26, -19, 29, 3, 86, -27, 52, -17, 10, -80, -75, 26, 34, 29, 88, 53, -38, -38, 21, -13, 96, 25, 51, -9, 45, -13, -78, 13, 38, 18, 32, 48, -26, -37, 15, 25, 59, 32, 80, 11, 29, -23, -92, 8, -12, 35, 50, 16, -15, -39, 11, -22, 57, 10, 48, -36, 47, -21, -7, 87, 15, -71, 20, 45, 14, 16, 39, 19, 18, 
  13, -2, 17, -2, -12, -9, 24, -42, -25, -25, 19, -12, -13, -18, -24, 32, 39, 11, 16, -10, 6, -29, 19, -18, -8, -16, -1, 0, -21, 34, -7, 30, 50, 30, -5, -15, 17, -2, 10, 14, -30, -24, 29, 22, -22, 12, 9, 22, -9, 41, -32, -10, 7, -48, 82, 10, 8, -26, 20, 43, 4, -33, -20, -45, 28, 14, -12, -35, -6, -22, 73, -3, 17, -54, 15, 23, -31, -37, -19, -31, 73, 0, 9, -37, -18, 2, -1, -19, -38, -14, 13, -11, 6, -67, -30, -31, -62, -27, -48, 0, 54, -71, -71, -6, -29, 1, -19, 31, -48, -55, 4, 17, -88, 24, -29, -54, 46, -17, -74, -73, -37, -10, -17, -8, 40, 23, 38, -28, -23, 2, 56, 26, 66, 50, -28, 25, -26, 34, 27, 0, 68, 66, 34, -43, -47, 27, 57, 35, 39, 50, 10, 52, 0, 7, -38, 18, 49, 24, 4, -76, -7, -45, 35, 20, 27, 1, 53, 16, -1, -1, -42, -42, 27, 16, 19, -12, -30, -52, 58, -3, 46, 39, 7, -12, -26, 38, -18, -36, 30, 7, 51, -18, -21, -4, 55, 7, 48, -15, -48, 4, -11, 30, -39, -46, 16, -14, -18, 8, -75, -61, 15, 8, 16, 26, -3, -39, -23, 9, -18, -23, 12, -18, 20, -47, 
  -10, 5, 24, 25, 33, 22, 16, 5, -3, 44, -8, -28, 33, 41, 25, -48, -51, 17, -16, 17, 2, -8, 7, 7, -47, 30, -53, -19, -12, -22, -24, -20, -52, -2, 21, -14, 49, 38, -21, 52, -58, -22, 19, 0, -5, 10, 32, -20, -44, 45, 59, 1, 85, 56, -28, 42, -45, 13, -19, -4, 34, 11, 55, 49, -17, 40, 76, 21, 48, 23, -7, 22, -59, -17, -9, 1, 29, 53, 32, -34, -11, 15, 68, 21, 42, 47, -5, 4, -12, -39, 14, 27, 56, 24, 95, -65, -19, 24, 10, -2, -3, 17, 24, -22, -59, 1, -12, 5, 29, -22, 19, -39, -50, -12, 34, -19, 10, -5, 104, 35, -39, 19, -70, -12, -9, 26, -15, -42, -84, -11, -15, -40, 21, -22, -3, -8, -9, -16, -14, -19, -14, -50, 6, -5, -59, -19, -43, -30, 2, -18, -4, -26, -71, 37, -42, 31, -38, -21, 2, -10, 3, -11, -44, -46, -40, -37, -3, 23, -40, -14, -33, -8, -32, -38, 29, -7, 27, 38, -38, -35, -9, -14, 3, 18, -59, -38, -4, 37, -38, -27, 29, 27, 10, 65, -17, 3, -14, 27, 0, -18, -9, -23, 22, 28, -17, -16, 13, -18, 20, 59, -17, 7, -2, 5, -49, -21, -14, 25, 23, 34, 2, 9, 10, -14, 
  20, 42, 48, 23, 34, -12, 4, 6, 4, 64, -18, 33, 3, 60, 49, 57, 20, 31, 6, 44, 46, -20, 20, 56, -31, 43, -33, 2, 20, 24, 55, 24, -11, 49, 25, -1, 6, -1, 54, 74, 1, 16, -18, 15, -30, 22, 0, -6, -36, -32, -38, -44, -30, 32, 15, 57, -46, -42, -30, 33, -3, 17, 2, 22, 9, -5, -42, -66, -65, 36, 42, 56, 2, -46, -14, -37, -11, 11, -22, 28, -8, -11, -2, -54, -40, -23, 38, -18, -18, 22, -23, -25, -10, -13, -45, 72, 36, -49, -35, -24, 6, 4, 4, -2, -34, -7, -11, -6, -35, 6, -4, 49, 17, -32, -18, -19, -16, -20, -1, -12, -28, 8, 26, 19, -20, 31, -9, 84, 28, -4, 30, -41, -40, -6, 43, 29, -70, -6, 43, 19, 19, -12, 29, -7, 16, 9, -6, -6, -24, -1, -17, 52, -12, 10, -2, -9, 15, 31, -28, 54, 38, 4, -8, -12, -1, 24, -8, 11, -65, -34, -53, -2, 18, -3, -39, 25, 38, -3, 7, -8, 10, -30, -3, 42, -54, 36, -2, 57, -38, 4, -30, -21, -11, -21, -16, -39, -23, -30, 127, 62, -43, 12, -32, 53, -54, 17, 33, 34, -22, -51, -32, -87, -77, -2, 66, 15, -75, 12, -108, 28, 31, 1, 30, 75, 
  -31, 33, -20, -24, 5, -7, 44, 17, -15, 14, 32, -17, 72, -15, 4, 66, 9, 35, 39, 17, -2, -12, -4, 5, -14, -17, -24, 34, 61, 27, -36, 93, 41, 14, 59, -1, -29, -11, 29, 44, 1, 2, -1, -33, 41, -64, 45, 93, -29, -15, 45, 20, -19, 5, -19, 8, 8, 59, -44, -39, 37, -46, 2, 56, -42, 14, 43, -2, -34, 39, -18, -13, -6, -33, -82, -20, 15, -42, -4, 15, -61, 26, 3, -27, -8, 15, -10, 26, -3, -2, -45, -11, 76, -27, -22, 75, -7, 25, 73, -4, -26, 8, 54, 34, 2, 20, -69, 30, 56, -17, 28, 5, -19, -32, 28, -71, 10, 16, -29, 2, 6, -75, -26, -33, 80, -69, -9, 5, -5, 34, 58, -6, -16, 33, 22, -10, -47, -28, -14, 17, 19, -21, 35, 67, -5, -25, 89, -1, -33, 7, 37, 17, -30, -22, -14, -22, 57, -24, -12, 74, -56, 17, 38, -30, 0, -9, 27, 22, -26, -24, -13, -49, 52, -28, -16, 31, -26, -15, -11, -23, -36, 2, 79, -47, -23, 18, -38, 11, 40, -26, -4, 65, -37, 22, 43, -10, -26, 49, 20, 8, -81, 25, -9, -31, 59, 37, 30, -2, -79, 6, 38, -6, -9, 34, 68, -2, -30, -13, -49, 10, -2, 20, 9, 17, 
  -38, -32, 19, 7, 36, 30, 40, 2, 47, -5, -11, -10, 0, 4, 38, 9, -13, -10, 55, -57, 40, 20, 56, -4, 26, 6, -5, -46, -5, -85, -40, 14, 21, -39, 66, 44, -51, 10, 25, -11, 19, 21, -28, -50, 55, -34, -2, 111, 1, -40, 68, 12, -22, 46, 30, -5, -1, 17, -37, 8, 81, -53, 29, 19, -35, -29, 74, -21, -27, 12, -16, 32, 44, 22, 2, 34, 63, -6, -58, 16, -40, -28, 11, 20, -63, 51, 17, 13, 35, -32, -26, 5, 59, 34, 18, 34, -68, 2, 47, -8, -49, -16, 35, -7, 13, -7, -112, 3, 61, -49, 13, 9, -69, -28, 14, -33, 16, 8, -5, 28, 6, -108, -48, -1, 41, -33, -30, 63, 50, -58, 13, -23, -15, 44, 16, 17, -78, -18, -57, -32, 76, -78, 7, 47, -38, 15, 39, -28, -28, 13, 9, -36, -52, -26, -24, -11, 42, -60, -44, 20, -9, -4, 38, -26, -21, 56, -16, -3, -34, -42, -102, 6, 42, 3, 27, 37, -16, -54, 29, -54, -28, 46, 83, -46, -35, 6, -50, -55, 40, -49, -7, 48, -56, -49, 1, -22, -69, 8, 69, -26, -96, -51, -33, -26, 50, 5, -26, -18, -75, -1, 10, -15, 3, 21, 48, 15, -7, -39, -50, -43, 32, -18, -28, -2, 
  12, 0, 29, 23, 23, 63, 44, -24, 43, -16, -27, -1, -1, 28, -14, 30, -3, -23, -28, 24, 33, 9, 47, -9, -36, 13, -8, 8, -4, 9, -40, -4, 27, -37, 9, -21, 34, 5, 28, -43, 61, -69, 55, -23, -26, -3, -30, -46, 13, -21, 27, 5, 1, 39, -60, -61, 75, -37, 52, 1, 11, -46, 10, 14, 40, -35, 9, 34, 33, 25, -48, -58, 44, -6, 4, -21, -20, 23, -38, 6, -11, -13, 18, 31, 25, 6, -40, -29, 22, -4, -37, 42, 41, -9, 36, -24, 48, -24, -10, -3, -14, 56, -38, 12, 68, -14, 38, 35, -11, -15, -11, 2, 40, 19, 50, -8, 32, 51, -57, 13, 73, -39, 58, 39, 24, -24, 14, 44, 19, -42, 11, 13, 7, 68, -19, -3, 25, -19, 10, 38, 43, -18, -2, 51, 29, -41, 44, -7, -12, -11, 1, -1, 23, -28, 26, 19, 37, -17, -17, -19, 5, -5, -15, -14, 6, -2, -33, -15, 78, -27, 58, 0, 32, -64, -10, 21, 69, -30, -10, -22, 58, 10, -37, -30, 73, -57, 18, 41, 5, -15, -59, -1, 47, -27, 40, 0, 51, 22, -10, 17, -1, -36, 35, -15, -12, -23, 10, 28, 92, -43, 5, 32, 32, 41, 33, 6, 27, -12, 64, 17, -3, -54, -27, 32, 
  5, 34, -9, 8, 4, 15, -36, -9, -46, 63, -23, 6, 0, 21, 32, -13, -35, 18, 30, -17, 42, -11, 32, 43, 31, 59, 27, 26, 25, 50, 26, -37, -52, 6, 2, 5, 51, 7, 1, 42, -35, 59, 38, 8, 24, 17, 45, -5, -25, 80, 39, 76, 91, 2, -20, 37, -43, 56, 61, 29, -6, -8, -7, -28, 26, -2, -10, 42, 26, 27, 59, 27, -32, 38, 32, 46, -31, 13, 59, -22, -21, -35, -29, 42, -5, -26, 7, 7, -65, 44, 9, 42, 37, 33, 25, -6, -16, 13, 12, 42, 69, 9, 13, 6, 29, 37, 54, -1, 34, 46, 34, 29, -18, 34, 20, 32, 16, 43, 2, 80, 15, 16, -34, 28, 19, 20, 36, -38, -92, 36, 23, 10, 12, -14, -24, 4, -11, 72, -32, -15, 15, 16, 58, 32, -48, 5, -20, -4, 57, -39, -12, 9, -6, 34, 48, -28, -2, 25, 23, 25, -20, 63, -35, 2, 49, 13, 46, 7, 33, 88, 55, 50, -8, 53, 74, 2, 17, 43, -6, -2, 8, -26, 12, 15, -57, 68, 27, 52, 3, -4, -20, 3, -23, 21, -29, -16, 33, -11, -49, -47, 1, 3, -6, 9, 0, 21, -32, 8, 19, 20, 0, 2, -9, 5, -5, 25, -33, -32, -7, 24, 22, 35, 57, -11, 
  9, -46, 10, 41, 14, 53, 63, -51, -20, 52, 2, -18, 8, -23, 6, -45, 0, 4, -8, 10, 3, 10, 75, 28, 25, 28, -35, -23, 3, 10, -42, -40, -11, 32, -18, -16, -34, -20, 32, 21, 60, -19, -7, -2, -9, -17, -4, -11, -62, -67, 0, -35, -65, -46, 2, 32, 6, 15, -91, -80, 16, -32, -24, 24, -69, -42, 16, -44, 4, -47, 34, 11, 35, 22, 4, -1, 18, -32, -23, 33, 6, -37, 13, -3, 44, -74, 28, 29, 39, 11, -19, -45, -11, -34, 45, 7, 17, -60, 35, -15, 50, -83, -13, -24, 63, 28, 11, -22, 13, -34, -17, 8, 32, -77, 50, -21, 55, -94, -53, 9, -6, 6, 1, 53, -7, 20, 49, 10, 10, -50, -10, -49, -4, -41, -36, 33, -2, 10, 26, 60, -12, 2, 28, 71, 38, -69, -1, -5, -30, 35, -33, -36, -20, 4, -17, 45, 1, 38, 3, -18, 23, -50, -29, -60, 25, -23, -2, 1, -41, -49, -17, 55, -23, 16, 10, -50, 50, -60, 32, -23, 6, 16, 64, 20, -57, -54, -27, 52, -25, 17, -32, -42, -21, -30, 4, -28, -69, 31, 33, 47, -87, -13, -74, 22, -42, 15, -18, -87, -5, -48, -9, -43, -73, 25, 21, 73, 1, -2, -69, 4, -11, 8, -71, -72, 
  -3, 20, 0, -17, 31, 7, -27, -1, 8, 3, -10, 41, 24, 32, -23, -90, 15, 21, 19, -9, 40, 18, -7, -8, 28, 11, 21, 3, -13, -9, 25, -16, -14, -9, -26, 29, 12, 20, 16, 24, 16, 1, 61, 35, 27, -13, 33, -28, 11, -22, -18, 91, 96, -3, -33, -22, 107, 44, 58, 42, 42, 35, 5, -43, 8, -2, 40, 56, 23, 34, -48, 5, 42, 11, 47, 29, 5, 40, 33, -56, 9, 9, 30, 42, 7, 44, -51, -13, 77, 20, 42, -14, 5, 36, -3, -45, 12, 6, 6, 71, 35, -25, -7, -19, 62, 13, 42, -11, 3, 38, 46, -33, -17, -40, 33, 42, 34, -78, 26, -34, 23, 71, 10, 5, -23, 13, -33, -15, 8, -18, -13, -19, 71, -69, -47, -30, 83, 9, 15, -22, -47, -26, -19, -38, -2, -48, -26, 23, 61, -19, -52, -9, 99, -3, 39, -28, -33, 12, 21, -9, 32, -12, -1, 23, 59, 8, -7, -23, 106, 6, 20, 19, -28, -10, -24, 16, 20, -33, 15, 9, -38, -8, -59, -28, 45, 12, 47, 2, -9, -22, -8, 6, 6, 3, -4, 16, -8, -43, -81, -33, 7, 22, 38, 21, -15, 34, -51, -12, -11, -5, 14, 27, -20, -14, -51, -16, 10, 33, 35, -7, 15, -10, -17, 25, 
};
const TfArray<2, int> tensor_dimension7 = { 2, { 20,224 } };
const TfArray<1, float> quant7_scale = { 1, { 0.0035071512684226036, } };
const TfArray<1, int> quant7_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant7 = { (TfLiteFloatArray*)&quant7_scale, (TfLiteIntArray*)&quant7_zero, 0 };
const ALIGN(16) int32_t tensor_data8[20] = { 375, 358, -826, -442, -140, 235, 506, 93, 97, 89, 386, -701, -593, 795, 953, 1029, 846, -947, 154, -624, };
const TfArray<1, int> tensor_dimension8 = { 1, { 20 } };
const TfArray<1, float> quant8_scale = { 1, { 0.00038751002284698188, } };
const TfArray<1, int> quant8_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&quant8_zero, 0 };
const ALIGN(16) int8_t tensor_data9[5*20] = { 
  38, -19, -88, -118, -112, -27, -27, -62, -93, 1, -51, -81, -58, 81, 48, 107, 67, -118, -54, -11, 
  -26, -110, 30, -19, -80, -83, -64, -31, -101, -7, -100, 111, 96, -38, 0, 41, -45, 36, -69, 78, 
  -81, 114, -36, -88, -91, -24, 94, 15, 52, 54, 126, -101, 59, 32, -54, -17, -89, -8, -95, -55, 
  -23, -82, -51, 35, 13, 92, 43, -53, -101, 9, -127, -63, -90, -73, -92, -19, 79, -37, -54, 114, 
  77, -7, -85, 42, 74, 32, 0, -87, 85, -88, 40, -68, -16, 103, -47, -44, -42, -58, 114, -72, 
};
const TfArray<2, int> tensor_dimension9 = { 2, { 5,20 } };
const TfArray<1, float> quant9_scale = { 1, { 0.0055740778334438801, } };
const TfArray<1, int> quant9_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&quant9_zero, 0 };
const ALIGN(16) int32_t tensor_data10[5] = { 697, -604, 124, -89, -85, };
const TfArray<1, int> tensor_dimension10 = { 1, { 5 } };
const TfArray<1, float> quant10_scale = { 1, { 0.0007243788568302989, } };
const TfArray<1, int> quant10_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&quant10_zero, 0 };
const TfArray<4, int> tensor_dimension11 = { 4, { 1,1,150,6 } };
const TfArray<1, float> quant11_scale = { 1, { 0.10501408576965332, } };
const TfArray<1, int> quant11_zero = { 1, { -1 } };
const TfLiteAffineQuantization quant11 = { (TfLiteFloatArray*)&quant11_scale, (TfLiteIntArray*)&quant11_zero, 0 };
const TfArray<4, int> tensor_dimension12 = { 4, { 1,1,48,16 } };
const TfArray<1, float> quant12_scale = { 1, { 0.065640635788440704, } };
const TfArray<1, int> quant12_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant12 = { (TfLiteFloatArray*)&quant12_scale, (TfLiteIntArray*)&quant12_zero, 0 };
const TfArray<4, int> tensor_dimension13 = { 4, { 1,1,14,16 } };
const TfArray<1, float> quant13_scale = { 1, { 0.11049138754606247, } };
const TfArray<1, int> quant13_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant13 = { (TfLiteFloatArray*)&quant13_scale, (TfLiteIntArray*)&quant13_zero, 0 };
const TfArray<2, int> tensor_dimension14 = { 2, { 1,224 } };
const TfArray<1, float> quant14_scale = { 1, { 0.11049138754606247, } };
const TfArray<1, int> quant14_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant14 = { (TfLiteFloatArray*)&quant14_scale, (TfLiteIntArray*)&quant14_zero, 0 };
const TfArray<2, int> tensor_dimension15 = { 2, { 1,20 } };
const TfArray<1, float> quant15_scale = { 1, { 0.12995491921901703, } };
const TfArray<1, int> quant15_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant15 = { (TfLiteFloatArray*)&quant15_scale, (TfLiteIntArray*)&quant15_zero, 0 };
const TfArray<2, int> tensor_dimension16 = { 2, { 1,5 } };
const TfArray<1, float> quant16_scale = { 1, { 0.33568382263183594, } };
const TfArray<1, int> quant16_zero = { 1, { 33 } };
const TfLiteAffineQuantization quant16 = { (TfLiteFloatArray*)&quant16_scale, (TfLiteIntArray*)&quant16_zero, 0 };
const TfArray<2, int> tensor_dimension17 = { 2, { 1,5 } };
const TfArray<1, float> quant17_scale = { 1, { 0.00390625, } };
const TfArray<1, int> quant17_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant17 = { (TfLiteFloatArray*)&quant17_scale, (TfLiteIntArray*)&quant17_zero, 0 };
const TfLiteReshapeParams opdata0 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs0 = { 2, { 0,1 } };
const TfArray<1, int> outputs0 = { 1, { 11 } };
const TfLiteConvParams opdata1 = { kTfLitePaddingValid, 3,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs1 = { 3, { 11,3,4 } };
const TfArray<1, int> outputs1 = { 1, { 12 } };
const TfLiteConvParams opdata2 = { kTfLitePaddingValid, 3,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs2 = { 3, { 12,5,6 } };
const TfArray<1, int> outputs2 = { 1, { 13 } };
const TfLiteReshapeParams opdata3 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs3 = { 2, { 13,2 } };
const TfArray<1, int> outputs3 = { 1, { 14 } };
const TfLiteFullyConnectedParams opdata4 = { kTfLiteActRelu, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs4 = { 3, { 14,7,8 } };
const TfArray<1, int> outputs4 = { 1, { 15 } };
const TfLiteFullyConnectedParams opdata5 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs5 = { 3, { 15,9,10 } };
const TfArray<1, int> outputs5 = { 1, { 16 } };
const TfLiteSoftmaxParams opdata6 = { 1 };
const TfArray<1, int> inputs6 = { 1, { 16 } };
const TfArray<1, int> outputs6 = { 1, { 17 } };
const TensorInfo_t tensorData[] = {
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 912, (TfLiteIntArray*)&tensor_dimension0, 900, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant0))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data1, (TfLiteIntArray*)&tensor_dimension1, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data2, (TfLiteIntArray*)&tensor_dimension2, 8, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data3, (TfLiteIntArray*)&tensor_dimension3, 864, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant3))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data4, (TfLiteIntArray*)&tensor_dimension4, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant4))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data5, (TfLiteIntArray*)&tensor_dimension5, 2304, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant5))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data6, (TfLiteIntArray*)&tensor_dimension6, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant6))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data7, (TfLiteIntArray*)&tensor_dimension7, 4480, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant7))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data8, (TfLiteIntArray*)&tensor_dimension8, 80, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant8))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data9, (TfLiteIntArray*)&tensor_dimension9, 100, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant9))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data10, (TfLiteIntArray*)&tensor_dimension10, 20, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant10))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension11, 900, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant11))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 912, (TfLiteIntArray*)&tensor_dimension12, 768, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant12))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 576, (TfLiteIntArray*)&tensor_dimension13, 224, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant13))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension14, 224, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant14))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 224, (TfLiteIntArray*)&tensor_dimension15, 20, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant15))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 16, (TfLiteIntArray*)&tensor_dimension16, 5, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant16))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension17, 5, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant17))}, },
};const NodeInfo_t nodeData[] = {
  { (TfLiteIntArray*)&inputs0, (TfLiteIntArray*)&outputs0, const_cast<void*>(static_cast<const void*>(&opdata0)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs1, (TfLiteIntArray*)&outputs1, const_cast<void*>(static_cast<const void*>(&opdata1)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs2, (TfLiteIntArray*)&outputs2, const_cast<void*>(static_cast<const void*>(&opdata2)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs3, (TfLiteIntArray*)&outputs3, const_cast<void*>(static_cast<const void*>(&opdata3)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs4, (TfLiteIntArray*)&outputs4, const_cast<void*>(static_cast<const void*>(&opdata4)), OP_FULLY_CONNECTED, },
  { (TfLiteIntArray*)&inputs5, (TfLiteIntArray*)&outputs5, const_cast<void*>(static_cast<const void*>(&opdata5)), OP_FULLY_CONNECTED, },
  { (TfLiteIntArray*)&inputs6, (TfLiteIntArray*)&outputs6, const_cast<void*>(static_cast<const void*>(&opdata6)), OP_SOFTMAX, },
};
static void* overflow_buffers[EI_MAX_OVERFLOW_BUFFER_COUNT];
static size_t overflow_buffers_ix = 0;
static void * AllocatePersistentBuffer(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  if (current_location - bytes < tensor_boundary) {
    if (overflow_buffers_ix > EI_MAX_OVERFLOW_BUFFER_COUNT - 1) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d, does not fit in tensor arena and reached EI_MAX_OVERFLOW_BUFFER_COUNT\n",
        (int)bytes);
      return NULL;
    }

    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers[overflow_buffers_ix++] = ptr;
    return ptr;
  }

  current_location -= bytes;

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}
typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;
static scratch_buffer_t scratch_buffers[EI_MAX_SCRATCH_BUFFER_COUNT];
static size_t scratch_buffers_ix = 0;

static TfLiteStatus RequestScratchBufferInArena(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  if (scratch_buffers_ix > EI_MAX_SCRATCH_BUFFER_COUNT - 1) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d, reached EI_MAX_SCRATCH_BUFFER_COUNT\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBuffer(ctx, b.bytes);
  if (!b.ptr) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffers[scratch_buffers_ix] = b;
  *buffer_idx = scratch_buffers_ix;

  scratch_buffers_ix++;

  return kTfLiteOk;
}

static void* GetScratchBuffer(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > (int)scratch_buffers_ix) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static TfLiteTensor* GetTensor(const struct TfLiteContext* context,
                               int tensor_idx) {
  return &tflTensors[tensor_idx];
}

static TfLiteEvalTensor* GetEvalTensor(const struct TfLiteContext* context,
                                       int tensor_idx) {
  return &tflEvalTensors[tensor_idx];
}

} // namespace

TfLiteStatus trained_model_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    ei_printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;
  ctx.AllocatePersistentBuffer = &AllocatePersistentBuffer;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArena;
  ctx.GetScratchBuffer = &GetScratchBuffer;
  ctx.GetTensor = &GetTensor;
  ctx.GetEvalTensor = &GetEvalTensor;
  ctx.tensors = tflTensors;
  ctx.tensors_size = 18;
  for (size_t i = 0; i < 18; ++i) {
    tflTensors[i].type = tensorData[i].type;
    tflEvalTensors[i].type = tensorData[i].type;
    tflTensors[i].is_variable = 0;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    tflTensors[i].allocation_type = tensorData[i].allocation_type;
#else
    tflTensors[i].allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
    tflTensors[i].bytes = tensorData[i].bytes;
    tflTensors[i].dims = tensorData[i].dims;
    tflEvalTensors[i].dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    if(tflTensors[i].allocation_type == kTfLiteArenaRw){
      uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

     tflTensors[i].data.data =  start;
     tflEvalTensors[i].data.data =  start;
    }
    else {
       tflTensors[i].data.data = tensorData[i].data;
       tflEvalTensors[i].data.data = tensorData[i].data;
    }
#else
    tflTensors[i].data.data = tensorData[i].data;
    tflEvalTensors[i].data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
    tflTensors[i].quantization = tensorData[i].quantization;
    if (tflTensors[i].quantization.type == kTfLiteAffineQuantization) {
      TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
      tflTensors[i].params.scale = quant->scale->data[0];
      tflTensors[i].params.zero_point = quant->zero_point->data[0];
    }
    if (tflTensors[i].allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tflTensors[i].data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }
  if (tensor_boundary > current_location /* end of arena size */) {
    ei_printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }
  registrations[OP_RESHAPE] = Register_RESHAPE();
  registrations[OP_CONV_2D] = Register_CONV_2D();
  registrations[OP_FULLY_CONNECTED] = Register_FULLY_CONNECTED();
  registrations[OP_SOFTMAX] = Register_SOFTMAX();

  for (size_t i = 0; i < 7; ++i) {
    tflNodes[i].inputs = nodeData[i].inputs;
    tflNodes[i].outputs = nodeData[i].outputs;
    tflNodes[i].builtin_data = nodeData[i].builtin_data;
tflNodes[i].custom_initial_data = nullptr;
      tflNodes[i].custom_initial_data_size = 0;
if (registrations[nodeData[i].used_op_index].init) {
      tflNodes[i].user_data = registrations[nodeData[i].used_op_index].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
    }
  }
  for (size_t i = 0; i < 7; ++i) {
    if (registrations[nodeData[i].used_op_index].prepare) {
      TfLiteStatus status = registrations[nodeData[i].used_op_index].prepare(&ctx, &tflNodes[i]);
      if (status != kTfLiteOk) {
        return status;
      }
    }
  }
  return kTfLiteOk;
}

static const int inTensorIndices[] = {
  0, 
};
TfLiteTensor* trained_model_input(int index) {
  return &ctx.tensors[inTensorIndices[index]];
}

static const int outTensorIndices[] = {
  17, 
};
TfLiteTensor* trained_model_output(int index) {
  return &ctx.tensors[outTensorIndices[index]];
}

TfLiteStatus trained_model_invoke() {
  for (size_t i = 0; i < 7; ++i) {
    TfLiteStatus status = registrations[nodeData[i].used_op_index].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus trained_model_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif

  // scratch buffers are allocated within the arena, so just reset the counter so memory can be reused
  scratch_buffers_ix = 0;

  // overflow buffers are on the heap, so free them first
  for (size_t ix = 0; ix < overflow_buffers_ix; ix++) {
    ei_free(overflow_buffers[ix]);
  }
  overflow_buffers_ix = 0;
  return kTfLiteOk;
}
